---
title: 迈出了爬虫的第一步
tags: [coding, 码农, python, 爬虫]
categories:
  - 金融狗在假装码农
photos: []
author: Mr.K
top: 0
date: 2020-02-17 18:34:09
---
今天趁着在家“怠”工的机会，因为不断要处理各种事情，所以没法专心学SciPy。只能随便撸一下爬虫的东西，同时因为爬虫，发现这两项需要好好研究一下。
<!-- more --> 

## 爬虫功能
这个爬虫的功能其实很单一，网上找到大神做的反代理[豆瓣Api](https://douban.uieee.com/)，可以获取和影视相关的素材，结合我之前打算复刻一个简易的豆瓣，所以爬点电影相关的数据回来。

这个爬虫的思路也很原始，真的是从一个点开始爬，真的让我发现人和人之间是有各种牵丝万缕的联系的。

我当时想法很简单，脑子里蹦出一个演员“姜文”，就是你了。先从豆瓣上找到姜文的id，然后输入给api，获取了第一个json，里面包括了姜文参演的47部作品以及每部作品的其他演员、导演等等。

当然每个人的id也都在json中，于是就是循环！找到这个人的id，去api上抓数据，返回，保存本地，然后循环在本地里看每个人的相关联的人物，如果和之前已经生成的重复了，就跳过，否则就创建一个新的json文件。如此往复。没有任何对人物关系的优化。

但尽管这么糙的程序，仍旧花了我小半天来写，跑起来之后，我还是被爬虫的能力惊艳到了。短短半个小时，爬回来了有700个人的资料。

## 效率仍有待提高
半小时700个file，尽管要open close write read for这些操作，但效率还是太低。于是我就开始去研究多线程和多进程。这个是我以往从来没有接触过的。分析了一下，多进程似乎更复杂一点，涉及到更多的比如数据重复等等问题，而且我这个数据I/O类型的，所以我选择了多进程。

一上来没什么经验，因为for循环，一下把threading加到了几千；电脑瞬间起飞LOL。然后就研究如何控制线程数等等。这块还有不少空间可以去了解，对于CPU密集型的任务，尤其是在数据分析中，多进程、多线程还是非常普遍的。

## 数据库怎么搞
好了，现在run了一下，已经有1700多个json文档了，每个都是一个演员的豆瓣信息，怎么处理？肯定不可能是放在json里面吧，关系型数据库就显得很必要了。可SQL怎么弄，又难到我了。这个也得学。。。

我尝试着结合Django去弄，虽然磕磕绊绊，但好歹也有些进展。晚上再试试看。